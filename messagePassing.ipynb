{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[705, 1], edge_index=[2, 1522], edge_attr=[1522], y=[32], batch=[705], ptr=[33])\n",
      "DataBatch(x=[705, 1], edge_index=[2, 1522], edge_attr=[1522], y=[32], batch=[705], ptr=[33], rrwp=[705, 8], rrwp_index=[2, 12605], rrwp_val=[12605, 8], log_deg=[705], deg=[705])\n",
      "torch.Size([2, 12605])\n",
      "torch.Size([12605])\n",
      "DataBatch(x=[705, 1], edge_index=[2, 1522], edge_attr=[1522], y=[32], batch=[705], ptr=[33], rrwp=[705, 8], rrwp_index=[2, 12605], rrwp_val=[12605, 8], log_deg=[705], deg=[705], expanded_edge_index=[2, 12605], expanded_edge_attr=[12605])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import ZINC\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "root = \"datasets/ZINC\"\n",
    "dataset = ZINC(root, subset=True, split=\"train\")\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for step, batch in enumerate(train_loader):\n",
    "    if step == 0:\n",
    "        # print(batch.batch)\n",
    "        # print(batch.batch.shape)\n",
    "        # print(batch.x.shape)\n",
    "        # print(batch.x)\n",
    "        data = batch\n",
    "        # print(batch.subgraph_idx_batch)\n",
    "        # print(batch)\n",
    "        break\n",
    "print(data)\n",
    "data = add_full_rrwp(data)\n",
    "print(data)\n",
    "expanded_edge_val_dummy = torch.zeros(data.rrwp_index.shape[1], dtype=torch.int64)\n",
    "expanded_edge_index, expanded_edge_val = torch_sparse.coalesce(torch.cat([data.edge_index, data.rrwp_index], dim=1), \n",
    "                    torch.cat([data.edge_attr, expanded_edge_val_dummy], dim=0), data.num_nodes, data.num_nodes,\n",
    "                    op=\"add\")\n",
    "print(expanded_edge_index.shape)\n",
    "print(expanded_edge_val.shape)\n",
    "data.expanded_edge_index = expanded_edge_index\n",
    "data.expanded_edge_attr = expanded_edge_val\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Any, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_scatter import scatter, scatter_add, scatter_max\n",
    "\n",
    "from torch_geometric.graphgym.config import cfg\n",
    "\n",
    "from torch_geometric.utils import (\n",
    "    get_laplacian,\n",
    "    get_self_loop_attr,\n",
    "    to_scipy_sparse_matrix,\n",
    ")\n",
    "import torch_sparse\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "def add_node_attr(data: Data, value: Any,\n",
    "                  attr_name: Optional[str] = None) -> Data:\n",
    "    if attr_name is None:\n",
    "        if 'x' in data:\n",
    "            x = data.x.view(-1, 1) if data.x.dim() == 1 else data.x\n",
    "            data.x = torch.cat([x, value.to(x.device, x.dtype)], dim=-1)\n",
    "        else:\n",
    "            data.x = value\n",
    "    else:\n",
    "        data[attr_name] = value\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def add_full_rrwp(data,\n",
    "                  walk_length=8,\n",
    "                  attr_name_abs=\"rrwp\", # name: 'rrwp'\n",
    "                  attr_name_rel=\"rrwp\", # name: ('rrwp_idx', 'rrwp_val')\n",
    "                  add_identity=True,\n",
    "                  spd=False,\n",
    "                  **kwargs\n",
    "                  ):\n",
    "    device=data.edge_index.device\n",
    "    ind_vec = torch.eye(walk_length, dtype=torch.float, device=device)\n",
    "    num_nodes = data.num_nodes\n",
    "    edge_index, edge_weight = data.edge_index, data.edge_weight\n",
    "\n",
    "    adj = SparseTensor.from_edge_index(edge_index, edge_weight,\n",
    "                                       sparse_sizes=(num_nodes, num_nodes),\n",
    "                                       )\n",
    "\n",
    "    # Compute D^{-1} A:\n",
    "    deg = adj.sum(dim=1)\n",
    "    deg_inv = 1.0 / adj.sum(dim=1)\n",
    "    deg_inv[deg_inv == float('inf')] = 0\n",
    "    adj = adj * deg_inv.view(-1, 1)\n",
    "    adj = adj.to_dense()\n",
    "\n",
    "    pe_list = []\n",
    "    i = 0\n",
    "    if add_identity:\n",
    "        pe_list.append(torch.eye(num_nodes, dtype=torch.float))\n",
    "        i = i + 1\n",
    "\n",
    "    out = adj\n",
    "    pe_list.append(adj)\n",
    "\n",
    "    if walk_length > 2:\n",
    "        for j in range(i + 1, walk_length):\n",
    "            out = out @ adj\n",
    "            pe_list.append(out)\n",
    "\n",
    "    pe = torch.stack(pe_list, dim=-1) # n x n x k\n",
    "\n",
    "    abs_pe = pe.diagonal().transpose(0, 1) # n x k\n",
    "\n",
    "    rel_pe = SparseTensor.from_dense(pe, has_value=True)\n",
    "    rel_pe_row, rel_pe_col, rel_pe_val = rel_pe.coo()\n",
    "    rel_pe_idx = torch.stack([rel_pe_row, rel_pe_col], dim=0)\n",
    "\n",
    "    if spd:\n",
    "        spd_idx = walk_length - torch.arange(walk_length)\n",
    "        val = (rel_pe_val > 0).type(torch.float) * spd_idx.unsqueeze(0)\n",
    "        val = torch.argmax(val, dim=-1)\n",
    "        rel_pe_val = F.one_hot(val, walk_length).type(torch.float)\n",
    "        abs_pe = torch.zeros_like(abs_pe)\n",
    "\n",
    "    data = add_node_attr(data, abs_pe, attr_name=attr_name_abs)\n",
    "    data = add_node_attr(data, rel_pe_idx, attr_name=f\"{attr_name_rel}_index\")\n",
    "    data = add_node_attr(data, rel_pe_val, attr_name=f\"{attr_name_rel}_val\")\n",
    "    data.log_deg = torch.log(deg + 1)\n",
    "    data.deg = deg.type(torch.long)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_geometric.typing import OptPairTensor\n",
    "from torch_geometric.graphgym.models.layer import LayerConfig\n",
    "from torch_geometric.graphgym.register import register_layer\n",
    "from torch_geometric.nn import Linear as Linear_pyg\n",
    "\n",
    "\n",
    "\n",
    "class FilteredGINELayer(pyg_nn.conv.MessagePassing):\n",
    "    \"\"\"GINEConv Layer with Filtration implementation.\n",
    "\n",
    "    Modified torch_geometric.nn.conv.GINECon layer to perform learned message scaling\n",
    "    according to graph_encoding\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nn, eps=0., train_eps=False, edge_dim=None, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(**kwargs)\n",
    "        self.nn = nn\n",
    "        self.initial_eps = eps\n",
    "        if train_eps:\n",
    "            self.eps = torch.nn.Parameter(torch.Tensor([eps]))\n",
    "        else:\n",
    "            self.register_buffer('eps', torch.Tensor([eps]))\n",
    "        if edge_dim is not None:\n",
    "            if isinstance(self.nn, torch.nn.Sequential):\n",
    "                nn = self.nn[0]\n",
    "            if hasattr(nn, 'in_features'):\n",
    "                in_channels = nn.in_features\n",
    "            elif hasattr(nn, 'in_channels'):\n",
    "                in_channels = nn.in_channels\n",
    "            else:\n",
    "                raise ValueError(\"Could not infer input channels from `nn`.\")\n",
    "            self.lin = pyg_nn.Linear(edge_dim, in_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "        self.reset_parameters()\n",
    "\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        pyg_nn.inits.reset(self.nn)\n",
    "        self.eps.data.fill_(self.initial_eps)\n",
    "        if self.lin is not None:\n",
    "            self.lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None, mask=None, size=None):\n",
    "        if isinstance(x, Tensor):\n",
    "            x: OptPairTensor = (x, x)\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr, mask=mask)\n",
    "        \n",
    "        x_r = x[1]\n",
    "        if x_r is not None:\n",
    "            out += (1 + self.eps) * x_r\n",
    "\n",
    "        return self.nn(out)\n",
    "    \n",
    "    def message(self, x_j, edge_attr, mask):\n",
    "        if self.lin is None and x_j.size(-1) != edge_attr.size(-1):\n",
    "            raise ValueError(\"Node and edge feature dimensionalities do not \"\n",
    "                    \"match. Consider setting the 'edge_dim' \"\n",
    "                    \"attribute of 'GINEConv'\")\n",
    "        print(\"x_j\", x_j.shape)\n",
    "        print(\"edge_attr: \", edge_attr.shape)\n",
    "        if self.lin is not None:\n",
    "            edge_attr = self.lin(edge_attr)\n",
    "        return torch.einsum('i,ij->ij', mask, (x_j + edge_attr).relu())\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}(nn={self.nn})'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13836])\n",
      "torch.Size([13836, 8])\n",
      "torch.Size([2, 13836])\n",
      "torch.Size([13836, 8])\n"
     ]
    }
   ],
   "source": [
    "# data = add_full_rrwp(data)\n",
    "# import torch_sparse\n",
    "# rrwp_idx = data.rrwp_index\n",
    "# rrwp_val = data.rrwp_val\n",
    "# edge_index = data.edge_index\n",
    "# edge_attr = torch.rand([edge_index.shape[1], rrwp_val.shape[1]])\n",
    "\n",
    "# if edge_attr is None:\n",
    "#     edge_attr = edge_index.new_zeros(edge_index.size(1), rrwp_val.size(1))\n",
    "#     # zero padding for non-existing edges\n",
    "\n",
    "# out_idx, out_val = torch_sparse.coalesce(\n",
    "#     torch.cat([edge_index, rrwp_idx], dim=1),\n",
    "#     torch.cat([edge_attr, rrwp_val], dim=0),\n",
    "#     batch.num_nodes, batch.num_nodes,\n",
    "#     op=\"add\"\n",
    "#         )\n",
    "\n",
    "# print(rrwp_idx.shape)\n",
    "# print(rrwp_val.shape)\n",
    "# print(out_idx.shape)\n",
    "# print(out_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0,  ..., 0, 1, 0])\n",
      "x_j torch.Size([12605, 21])\n",
      "edge_attr:  torch.Size([12605, 21])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.nn as pyg_nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dim_in = 21\n",
    "dim_out = 64\n",
    "num_clusters = 5\n",
    "mlp = nn.Sequential(pyg_nn.Linear(dim_in, dim_out), nn.ReLU(),\n",
    "                    pyg_nn.Linear(dim_out, dim_out))\n",
    "gineLayer = FilteredGINELayer(mlp)\n",
    "\n",
    "encoding = torch.randn([data.rrwp_val.shape[0], num_clusters])\n",
    "masks = F.softmax(encoding, dim=-1)\n",
    "# print(masks.shape)\n",
    "masks = torch.transpose(masks, 0, 1)\n",
    "# print(masks.shape)\n",
    "# print(masks[0].shape)\n",
    "one_vec = torch.ones([masks.shape[1], 3])\n",
    "# print(masks[0])\n",
    "# print(torch.einsum('i,ij->ij', masks[0], one_vec))\n",
    "h = torch.randn([data.x.shape[0], dim_in])\n",
    "encoder = torch.nn.Embedding(num_embeddings=4, embedding_dim=dim_in)\n",
    "print(data.expanded_edge_attr)\n",
    "expanded_edge_attr = encoder(data.expanded_edge_attr)\n",
    "x = gineLayer(h, data.expanded_edge_index, expanded_edge_attr, masks[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphgps_copy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
